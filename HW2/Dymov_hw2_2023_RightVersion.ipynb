{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBrDXMdDy-Qn"
      },
      "source": [
        "# HSE 2023: Введение в машинное обучение БИ 23/24\n",
        "\n",
        "## ДЗ 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXXi5K1mf41d"
      },
      "source": [
        "# Внимание!\n",
        "Если в задании просят объяснить что-либо, то это значит, что требуется письменный ответ, который является частью задания и оценивается\n",
        "\n",
        "Мы только принимаем ipynb ноутбуки. Если вы используете Google Colab, то вам необходимо скачать ноутбук перед сдачей ДЗ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-09-26T16:48:20.566549Z",
          "start_time": "2020-09-26T16:48:19.893995Z"
        },
        "id": "mSR-a9vVy-Qp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn import datasets\n",
        "# from sklearn.datasets import load_boston\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from statsmodels.regression.linear_model import OLSResults\n",
        "from math import sqrt\n",
        "import random\n",
        "import sys\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "sns.set(style=\"darkgrid\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUjuv9Qty-Qq"
      },
      "source": [
        "### Данные\n",
        "\n",
        "Для этого ДЗ мы будем использовать датасет треков со стримингового сервиса Spotify"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v71PNKo0yfYo"
      },
      "source": [
        "**Описание данных**\n",
        "\n",
        "- **track_id:** The Spotify ID for the track\n",
        "- **artists:** The artists' names who performed the track. If there is more than one artist, they are separated by a ;\n",
        "- **album_name:** The album name in which the track appears\n",
        "- **track_name:** Name of the track\n",
        "- **popularity:** The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are. Generally speaking, songs that are being played a lot now will have a higher popularity than songs that were played a lot in the past. Duplicate tracks (e.g. the same track from a single and an album) are rated independently. Artist and album popularity is derived mathematically from track popularity.\n",
        "- **duration_ms:** The track length in milliseconds\n",
        "- **explicit:** Whether or not the track has explicit lyrics (true = yes it does; false = no it does not OR unknown)\n",
        "- **danceability:** Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable\n",
        "- **key:** The key the track is in. Integers map to pitches using standard Pitch Class notation. E.g. 0 = C, 1 = C♯/D♭, 2 = D, and so on. If no key was detected, the value is -1\n",
        "- **loudness:** The overall loudness of a track in decibels (dB)\n",
        "- **mode:** Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0\n",
        "- **speechiness:** Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks\n",
        "- **acousticness:** A confidence measure from 0.0 to 1.0 of whether the track is acoustic. 1.0 represents high confidence the track is acoustic\n",
        "- **instrumentalness:** Predicts whether a track contains no vocals. \"Ooh\" and \"aah\" sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly \"vocal\". The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content\n",
        "- **liveness:** Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live\n",
        "- **valence:** A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry)\n",
        "- **tempo:** The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration\n",
        "- **time_signature:** An estimated time signature. The time signature (meter) is a notational convention to specify how many beats are in each bar (or measure). The time signature ranges from 3 to 7 indicating time signatures of 3/4, to 7/4.\n",
        "- **track_genre:** The genre in which the track belongs\n",
        "\n",
        "**Целевая переменная**\n",
        "- **energy:** Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy. For example, death metal has high energy, while a Bach prelude scores low on the scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tHWSWTXDy-Qq"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('dataset.csv')\n",
        "\n",
        "y = data['energy']\n",
        "X = data.drop(['energy'], axis=1)\n",
        "columns = X.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K81w8s35y-Qq"
      },
      "source": [
        "## Линейная регрессия"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYgEN-FMy-Qr"
      },
      "source": [
        "#### 0. [0.25 балла] Закодируйте категориальные признаки. Объясните выбранный вами метод."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответ: OneHotEncoder - сравнить влияние каждого жанра на трек и возможность оценки позже в регрессии, также я выбирал его из удобства работы и полезности для дальнейшей оценки"
      ],
      "metadata": {
        "id": "-ocBv_wUhs5S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-IrSlQaWy-Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "outputId": "379d12d9-d662-41b0-ddd0-7194464d15ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        popularity  duration_ms  explicit  danceability  key  loudness  mode  \\\n",
              "0               73       230666     False         0.676    1    -6.746     0   \n",
              "1               55       149610     False         0.420    1   -17.235     1   \n",
              "2               57       210826     False         0.438    0    -9.734     1   \n",
              "3               71       201933     False         0.266    0   -18.515     1   \n",
              "4               82       198853     False         0.618    2    -9.681     1   \n",
              "...            ...          ...       ...           ...  ...       ...   ...   \n",
              "113995          21       384999     False         0.172    5   -16.393     1   \n",
              "113996          22       385000     False         0.174    0   -18.318     0   \n",
              "113997          22       271466     False         0.629    0   -10.895     0   \n",
              "113998          41       283893     False         0.587    7   -10.889     1   \n",
              "113999          22       241826     False         0.526    1   -10.204     0   \n",
              "\n",
              "        speechiness  acousticness  instrumentalness  ...  track_genre_spanish  \\\n",
              "0            0.1430        0.0322          0.000001  ...                    0   \n",
              "1            0.0763        0.9240          0.000006  ...                    0   \n",
              "2            0.0557        0.2100          0.000000  ...                    0   \n",
              "3            0.0363        0.9050          0.000071  ...                    0   \n",
              "4            0.0526        0.4690          0.000000  ...                    0   \n",
              "...             ...           ...               ...  ...                  ...   \n",
              "113995       0.0422        0.6400          0.928000  ...                    0   \n",
              "113996       0.0401        0.9940          0.976000  ...                    0   \n",
              "113997       0.0420        0.8670          0.000000  ...                    0   \n",
              "113998       0.0297        0.3810          0.000000  ...                    0   \n",
              "113999       0.0725        0.6810          0.000000  ...                    0   \n",
              "\n",
              "        track_genre_study  track_genre_swedish  track_genre_synth-pop  \\\n",
              "0                       0                    0                      0   \n",
              "1                       0                    0                      0   \n",
              "2                       0                    0                      0   \n",
              "3                       0                    0                      0   \n",
              "4                       0                    0                      0   \n",
              "...                   ...                  ...                    ...   \n",
              "113995                  0                    0                      0   \n",
              "113996                  0                    0                      0   \n",
              "113997                  0                    0                      0   \n",
              "113998                  0                    0                      0   \n",
              "113999                  0                    0                      0   \n",
              "\n",
              "        track_genre_tango  track_genre_techno  track_genre_trance  \\\n",
              "0                       0                   0                   0   \n",
              "1                       0                   0                   0   \n",
              "2                       0                   0                   0   \n",
              "3                       0                   0                   0   \n",
              "4                       0                   0                   0   \n",
              "...                   ...                 ...                 ...   \n",
              "113995                  0                   0                   0   \n",
              "113996                  0                   0                   0   \n",
              "113997                  0                   0                   0   \n",
              "113998                  0                   0                   0   \n",
              "113999                  0                   0                   0   \n",
              "\n",
              "        track_genre_trip-hop  track_genre_turkish  track_genre_world-music  \n",
              "0                          0                    0                        0  \n",
              "1                          0                    0                        0  \n",
              "2                          0                    0                        0  \n",
              "3                          0                    0                        0  \n",
              "4                          0                    0                        0  \n",
              "...                      ...                  ...                      ...  \n",
              "113995                     0                    0                        1  \n",
              "113996                     0                    0                        1  \n",
              "113997                     0                    0                        1  \n",
              "113998                     0                    0                        1  \n",
              "113999                     0                    0                        1  \n",
              "\n",
              "[114000 rows x 127 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a4f94b87-bd04-44bb-8b47-754bca29482c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>popularity</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>explicit</th>\n",
              "      <th>danceability</th>\n",
              "      <th>key</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>...</th>\n",
              "      <th>track_genre_spanish</th>\n",
              "      <th>track_genre_study</th>\n",
              "      <th>track_genre_swedish</th>\n",
              "      <th>track_genre_synth-pop</th>\n",
              "      <th>track_genre_tango</th>\n",
              "      <th>track_genre_techno</th>\n",
              "      <th>track_genre_trance</th>\n",
              "      <th>track_genre_trip-hop</th>\n",
              "      <th>track_genre_turkish</th>\n",
              "      <th>track_genre_world-music</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>73</td>\n",
              "      <td>230666</td>\n",
              "      <td>False</td>\n",
              "      <td>0.676</td>\n",
              "      <td>1</td>\n",
              "      <td>-6.746</td>\n",
              "      <td>0</td>\n",
              "      <td>0.1430</td>\n",
              "      <td>0.0322</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>55</td>\n",
              "      <td>149610</td>\n",
              "      <td>False</td>\n",
              "      <td>0.420</td>\n",
              "      <td>1</td>\n",
              "      <td>-17.235</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0763</td>\n",
              "      <td>0.9240</td>\n",
              "      <td>0.000006</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57</td>\n",
              "      <td>210826</td>\n",
              "      <td>False</td>\n",
              "      <td>0.438</td>\n",
              "      <td>0</td>\n",
              "      <td>-9.734</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0557</td>\n",
              "      <td>0.2100</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>71</td>\n",
              "      <td>201933</td>\n",
              "      <td>False</td>\n",
              "      <td>0.266</td>\n",
              "      <td>0</td>\n",
              "      <td>-18.515</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0363</td>\n",
              "      <td>0.9050</td>\n",
              "      <td>0.000071</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>82</td>\n",
              "      <td>198853</td>\n",
              "      <td>False</td>\n",
              "      <td>0.618</td>\n",
              "      <td>2</td>\n",
              "      <td>-9.681</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0526</td>\n",
              "      <td>0.4690</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113995</th>\n",
              "      <td>21</td>\n",
              "      <td>384999</td>\n",
              "      <td>False</td>\n",
              "      <td>0.172</td>\n",
              "      <td>5</td>\n",
              "      <td>-16.393</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0422</td>\n",
              "      <td>0.6400</td>\n",
              "      <td>0.928000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113996</th>\n",
              "      <td>22</td>\n",
              "      <td>385000</td>\n",
              "      <td>False</td>\n",
              "      <td>0.174</td>\n",
              "      <td>0</td>\n",
              "      <td>-18.318</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0401</td>\n",
              "      <td>0.9940</td>\n",
              "      <td>0.976000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113997</th>\n",
              "      <td>22</td>\n",
              "      <td>271466</td>\n",
              "      <td>False</td>\n",
              "      <td>0.629</td>\n",
              "      <td>0</td>\n",
              "      <td>-10.895</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0420</td>\n",
              "      <td>0.8670</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113998</th>\n",
              "      <td>41</td>\n",
              "      <td>283893</td>\n",
              "      <td>False</td>\n",
              "      <td>0.587</td>\n",
              "      <td>7</td>\n",
              "      <td>-10.889</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0297</td>\n",
              "      <td>0.3810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113999</th>\n",
              "      <td>22</td>\n",
              "      <td>241826</td>\n",
              "      <td>False</td>\n",
              "      <td>0.526</td>\n",
              "      <td>1</td>\n",
              "      <td>-10.204</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0725</td>\n",
              "      <td>0.6810</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114000 rows × 127 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4f94b87-bd04-44bb-8b47-754bca29482c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a4f94b87-bd04-44bb-8b47-754bca29482c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a4f94b87-bd04-44bb-8b47-754bca29482c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fbd83084-50ba-44c1-9255-a0914bcd52b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fbd83084-50ba-44c1-9255-a0914bcd52b6')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fbd83084-50ba-44c1-9255-a0914bcd52b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "X_df_notenc = pd.DataFrame(X.drop(['track_name', 'artists', 'album_name'], axis=1))\n",
        "X_df = pd.get_dummies(X_df_notenc, drop_first=True)\n",
        "X_df\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_df.info()\n",
        "len(np.unique(X_df_notenc['track_genre']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ReyKQZG2fasU",
        "outputId": "828f3675-1620-4b1b-de93-56122080a866"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 114000 entries, 0 to 113999\n",
            "Columns: 127 entries, popularity to track_genre_world-music\n",
            "dtypes: bool(1), float64(8), int64(5), uint8(113)\n",
            "memory usage: 23.7 MB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "114"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dVwP45Gy-Qr"
      },
      "source": [
        "#### 1. [0.25 балла] Разбейте данные на train и test с пропорцией 75:25 и random_state=7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "U7z8TIh5y-Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35fe983e-7cae-4e37-d2fe-37eb647cb64e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train features shape: (85500, 127)\n",
            "Test features shape: (28500, 127)\n",
            "Train target shape: (85500,)\n",
            "Test target shape: (28500,)\n"
          ]
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "train_features, test_features, train_target, test_target = train_test_split(X_df, y, test_size=0.25, random_state=7)\n",
        "print(\"Train features shape:\", train_features.shape)\n",
        "print(\"Test features shape:\", test_features.shape)\n",
        "print(\"Train target shape:\", train_target.shape)\n",
        "print(\"Test target shape:\", test_target.shape)\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7daIQRfKy-Qs",
        "tags": []
      },
      "source": [
        "#### 2. [0.75 балла] Обучите модели на train'е, исключив категориальные признаки, используя библиотеку StatsModels и примените ее к test'у; используйте $RMSE$ и $R ^ 2$ в качестве метрики качества. Попробуйте также применить реализации линейной регрессии из sklearn:\n",
        "\n",
        "* [`LinearRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html);\n",
        "* [`Ridge`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) with $\\alpha = 0.03$;\n",
        "* [`Lasso`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) with $\\alpha = 0.05$\n",
        "* [`ElasticNet`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) with $\\alpha = 0.01$, $l_{1}$_$ratio = 0.4$\n",
        "\n",
        "Не забывайте скейлить данные с помощью StandardScaler перед обучением моделей!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Bkbr5iFCy-Qs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf4b13dd-f324-40bd-bbce-8ac228947f30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StatsModels OLS:\n",
            "R2: 0.7650038163295098\n",
            "RMSE: 0.12150856959639446\n",
            "\n",
            "Slearn Linear Regression:\n",
            "R2: 0.7650038163295098\n",
            "RMSE: 0.12150856959639444\n",
            "\n",
            "Slearn Ridge:\n",
            "R2: 0.7650038189741655\n",
            "RMSE: 0.1215085689126635\n",
            "\n",
            "Slearn Lasso:\n",
            "R2: 0.6555593645544675\n",
            "RMSE: 0.1471071204791906\n",
            "\n",
            "Slearn ElasticNet:\n",
            "R2: 0.7612921836726962\n",
            "RMSE: 0.1224643900063975\n"
          ]
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "scaler = StandardScaler()\n",
        "train_scaled = scaler.fit_transform(train_features.select_dtypes(exclude=\"uint8\"))\n",
        "test_scaled = scaler.transform(test_features.select_dtypes(exclude=\"uint8\"))\n",
        "\n",
        "train_scaled_sm = sm.add_constant(train_scaled)\n",
        "model_sm = sm.OLS(train_target, train_scaled_sm).fit()\n",
        "\n",
        "# Slearn - лин регрессия\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(train_scaled, train_target)\n",
        "# Slearn - Ridge\n",
        "model_ridge = Ridge(alpha=0.03)\n",
        "model_ridge.fit(train_scaled, train_target)\n",
        "# Slearn - лассо\n",
        "model_lasso = Lasso(alpha=0.05)\n",
        "model_lasso.fit(train_scaled, train_target)\n",
        "# Slearn - ElasticNet\n",
        "model_elasticnet = ElasticNet(alpha=0.01, l1_ratio=0.4)\n",
        "model_elasticnet.fit(train_scaled, train_target)\n",
        "\n",
        "# предсказываем наши модели после тренировки\n",
        "test_scaled_sm = sm.add_constant(test_scaled)\n",
        "predictions_sm = model_sm.predict(test_scaled_sm)\n",
        "r2_sm = r2_score(test_target, predictions_sm)\n",
        "rmse_sm = mean_squared_error(test_target, predictions_sm, squared = False)\n",
        "\n",
        "predictions_lr = model_lr.predict(test_scaled)\n",
        "r2_lr = model_lr.score(test_scaled, test_target)\n",
        "rmse_lr = mean_squared_error(test_target, predictions_lr, squared = False)\n",
        "\n",
        "predictions_ridge = model_ridge.predict(test_scaled)\n",
        "r2_ridge = model_ridge.score(test_scaled, test_target)\n",
        "rmse_ridge = mean_squared_error(test_target, predictions_ridge, squared = False)\n",
        "\n",
        "predictions_lasso = model_lasso.predict(test_scaled)\n",
        "r2_lasso = model_lasso.score(test_scaled, test_target)\n",
        "rmse_lasso = mean_squared_error(test_target, predictions_lasso, squared = False)\n",
        "\n",
        "predictions_elasticnet = model_elasticnet.predict(test_scaled)\n",
        "r2_elasticnet = model_elasticnet.score(test_scaled, test_target)\n",
        "rmse_elasticnet = mean_squared_error(test_target, predictions_elasticnet, squared = False)\n",
        "# выводим результаты предсказаний\n",
        "print('StatsModels OLS:')\n",
        "print('R2:', r2_sm)\n",
        "print('RMSE:', rmse_sm)\n",
        "print()\n",
        "print('Slearn Linear Regression:')\n",
        "print('R2:', r2_lr)\n",
        "print('RMSE:', rmse_lr)\n",
        "print()\n",
        "print('Slearn Ridge:')\n",
        "print('R2:', r2_ridge)\n",
        "print('RMSE:', rmse_ridge)\n",
        "print()\n",
        "print('Slearn Lasso:')\n",
        "print('R2:', r2_lasso)\n",
        "print('RMSE:', rmse_lasso)\n",
        "print()\n",
        "print('Slearn ElasticNet:')\n",
        "print('R2:', r2_elasticnet)\n",
        "print('RMSE:', rmse_elasticnet)\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGb4HzQCyfYq"
      },
      "source": [
        "#### 3. [0.25 балла] Повторите шаги из предыдущего пункта, добавив категориальные признаки. Прокомментируйте изменения значений метрик качества\n",
        "\n",
        "Ответ/комментарий:\n",
        "\n",
        "1. StatsModels OLS:\n",
        "   - R2: 0.7988\n",
        "   - RMSE: 0.1124\n",
        "   Модель, основанная на методе наименьших квадратов OLS, имеет довольно высокий коэффициент детерминации R2, равный 0.7988, что указывает на то, что она хорошо объясняет вариабельность в данных. RMSE низкий, что говорит о хорошей точности модели. Благодаря добавки катег признаков по сравнению с прошлым заданием R2 повысилось, а RMSE наоброт упало, что показывает на меньшую вероятность ошибки обучения\n",
        "\n",
        "2. Slearn Linear Regression:\n",
        "   - R2: 0.7988\n",
        "   - RMSE: 0.1124\n",
        "   Модель предоставляет аналогичные результаты, как и StatsModels OLS, с R2 и RMSE, близкими к тем же значениям. Тут так же упали значение RMSE и возросло R2. Это объяснет вариабельность наших данных\n",
        "\n",
        "3. Slearn Ridge:\n",
        "   - R2: 0.7988\n",
        "   - RMSE: 0.1124\n",
        "\n",
        "   Модель является методом линейной регрессии, показывает почти идентичные результаты по R2 и RMSE с предыдущими пункатми. По сравнению с предыдущим заданием аналогичные результаты наблюдаем по изменениям.\n",
        "\n",
        "4. Slearn Lasso:\n",
        "   - R2: 0.6556\n",
        "   - RMSE: 0.1471\n",
        "   Модель имеет более низкое значение R2, такое может указывать на то, что она хуже подходит для объяснения вариабельности в данных, чем другие. RMSE выше, что означает, что она может допускать большие ошибки при прогнозировании. По сравнению с предыдущим заданием значения практиечски не изменились\n",
        "\n",
        "5. Slearn ElasticNet:\n",
        "   - R2: 0.7803\n",
        "   - RMSE: 0.1175\n",
        "   Данная модель - это комбинация L1 и L2 регуляризации. Предоставляет средние значения R2 и RMSE по сравнению с другими моделями. Она может быть полезна, если есть как разреженные, так и коррелированные признаки(всопмним матстат).\n",
        "   В общем и целом, по сравнению с прошлым заданеим без катег признаков повысилась точность модели и понизилась вероятность ошибки, но ячейка отрабатывала больше чем предыдущая. Модель обучалась дольше\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOBHGnk_yfYq",
        "outputId": "a1172778-789f-4f19-ae89-74654528501e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "StatsModels OLS:\n",
            "R2: 0.798817701226791\n",
            "RMSE: 0.11242719795086324\n",
            "\n",
            "Slearn Linear Regression:\n",
            "R2: 0.7988177012267911\n",
            "RMSE: 0.11242719795086323\n",
            "\n",
            "Slearn Ridge:\n",
            "R2: 0.7988177062258259\n",
            "RMSE: 0.11242719655405176\n",
            "\n",
            "Slearn Lasso:\n",
            "R2: 0.6555593645544675\n",
            "RMSE: 0.1471071204791906\n",
            "\n",
            "Slearn ElasticNet:\n",
            "R2: 0.7803407980379423\n",
            "RMSE: 0.11747655554996232\n"
          ]
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "train_features1, test_features1, train_target1, test_target1 = train_test_split(X_df, y, test_size=0.25, random_state=7)\n",
        "scaler = StandardScaler()\n",
        "train_scaled1 = scaler.fit_transform(train_features1)\n",
        "test_scaled1 = scaler.transform(test_features1)\n",
        "\n",
        "train_scaled_sm1 = sm.add_constant(train_scaled1)\n",
        "model_sm1 = sm.OLS(train_target1, train_scaled_sm1).fit()\n",
        "\n",
        "# Slearn - лин регрессия\n",
        "model_lr = LinearRegression()\n",
        "model_lr.fit(train_scaled1, train_target1)\n",
        "# Slearn - Ridge\n",
        "model_ridge = Ridge(alpha=0.03)\n",
        "model_ridge.fit(train_scaled1, train_target1)\n",
        "# Slearn - лассо\n",
        "model_lasso = Lasso(alpha=0.05)\n",
        "model_lasso.fit(train_scaled1, train_target1)\n",
        "# Slearn - ElasticNet\n",
        "model_elasticnet = ElasticNet(alpha=0.01, l1_ratio=0.4)\n",
        "model_elasticnet.fit(train_scaled1, train_target1)\n",
        "# предсказания посмле тренировки можделей нанаших данных\n",
        "test_scaled_sm1 = sm.add_constant(test_scaled1)\n",
        "predictions_sm1 = model_sm1.predict(test_scaled_sm1)\n",
        "r2_sm1 = r2_score(test_target1, predictions_sm1)\n",
        "rmse_sm1 = mean_squared_error(test_target1, predictions_sm1, squared = False)\n",
        "predictions_lr1 = model_lr.predict(test_scaled1)\n",
        "r2_lr1 = model_lr.score(test_scaled1, test_target1)\n",
        "rmse_lr1 = mean_squared_error(test_target1, predictions_lr1, squared = False)\n",
        "predictions_ridge1 = model_ridge.predict(test_scaled1)\n",
        "r2_ridge1 = model_ridge.score(test_scaled1, test_target1)\n",
        "rmse_ridge1 = mean_squared_error(test_target1, predictions_ridge1, squared = False)\n",
        "predictions_lasso1 = model_lasso.predict(test_scaled1)\n",
        "r2_lasso1 = model_lasso.score(test_scaled1, test_target1)\n",
        "rmse_lasso1 = mean_squared_error(test_target1, predictions_lasso1, squared = False)\n",
        "predictions_elasticnet1 = model_elasticnet.predict(test_scaled1)\n",
        "r2_elasticnet1 = model_elasticnet.score(test_scaled1, test_target1)\n",
        "rmse_elasticnet1 = mean_squared_error(test_target1, predictions_elasticnet1, squared = False)\n",
        "# вывод результатов теперь\n",
        "print('StatsModels OLS:')\n",
        "print('R2:', r2_sm1)\n",
        "print('RMSE:', rmse_sm1)\n",
        "print()\n",
        "print('Slearn Linear Regression:')\n",
        "print('R2:', r2_lr1)\n",
        "print('RMSE:', rmse_lr1)\n",
        "print()\n",
        "print('Slearn Ridge:')\n",
        "print('R2:', r2_ridge1)\n",
        "print('RMSE:', rmse_ridge1)\n",
        "print()\n",
        "print('Slearn Lasso:')\n",
        "print('R2:', r2_lasso1)\n",
        "print('RMSE:', rmse_lasso1)\n",
        "print()\n",
        "print('Slearn ElasticNet:')\n",
        "print('R2:', r2_elasticnet1)\n",
        "print('RMSE:', rmse_elasticnet1)\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69JOftKRy-Qt"
      },
      "source": [
        "#### 4. [1 балл] Исследуйте значения параметров полученных моделей и проверьте какие веса получились нулевыми. Прокомментируйте значимость коэффициентов, обшую значимость модели и остальные факторы из результирующей таблицы\n",
        "\n",
        "Исследование: внизу\n",
        "\n",
        "Коментируем: внизу"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Np1biYQ7y-Qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "outputId": "c79efbc1-754a-406c-b2e5-418acbfd47a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                 energy   R-squared:                       0.766\n",
              "Model:                            OLS   Adj. R-squared:                  0.766\n",
              "Method:                 Least Squares   F-statistic:                 1.999e+04\n",
              "Date:                Sat, 21 Oct 2023   Prob (F-statistic):               0.00\n",
              "Time:                        17:46:01   Log-Likelihood:                 58684.\n",
              "No. Observations:               85500   AIC:                        -1.173e+05\n",
              "Df Residuals:                   85485   BIC:                        -1.172e+05\n",
              "Df Model:                          14                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6420      0.000   1540.996      0.000       0.641       0.643\n",
              "x1            -0.0021      0.000     -4.990      0.000      -0.003      -0.001\n",
              "x2             0.0048      0.000     11.313      0.000       0.004       0.006\n",
              "x3            -0.0018      0.000     -4.100      0.000      -0.003      -0.001\n",
              "x4            -0.0326      0.001    -64.317      0.000      -0.034      -0.032\n",
              "x5             0.0013      0.000      3.002      0.003       0.000       0.002\n",
              "x6             0.1352      0.001    226.522      0.000       0.134       0.136\n",
              "x7            -0.0040      0.000     -9.471      0.000      -0.005      -0.003\n",
              "x8             0.0279      0.000     61.646      0.000       0.027       0.029\n",
              "x9            -0.1062      0.001   -197.456      0.000      -0.107      -0.105\n",
              "x10            0.0350      0.000     71.180      0.000       0.034       0.036\n",
              "x11            0.0259      0.000     59.319      0.000       0.025       0.027\n",
              "x12            0.0411      0.001     80.905      0.000       0.040       0.042\n",
              "x13            0.0073      0.000     16.764      0.000       0.006       0.008\n",
              "x14            0.0061      0.000     14.048      0.000       0.005       0.007\n",
              "==============================================================================\n",
              "Omnibus:                     4795.339   Durbin-Watson:                   1.990\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            19490.754\n",
              "Skew:                           0.094   Prob(JB):                         0.00\n",
              "Kurtosis:                       5.331   Cond. No.                         2.77\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>energy</td>      <th>  R-squared:         </th>  <td>   0.766</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.766</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>1.999e+04</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 21 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:46:01</td>     <th>  Log-Likelihood:    </th>  <td>  58684.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 85500</td>      <th>  AIC:               </th> <td>-1.173e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 85485</td>      <th>  BIC:               </th> <td>-1.172e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6420</td> <td>    0.000</td> <td> 1540.996</td> <td> 0.000</td> <td>    0.641</td> <td>    0.643</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.0021</td> <td>    0.000</td> <td>   -4.990</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.0048</td> <td>    0.000</td> <td>   11.313</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0018</td> <td>    0.000</td> <td>   -4.100</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0326</td> <td>    0.001</td> <td>  -64.317</td> <td> 0.000</td> <td>   -0.034</td> <td>   -0.032</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0013</td> <td>    0.000</td> <td>    3.002</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.1352</td> <td>    0.001</td> <td>  226.522</td> <td> 0.000</td> <td>    0.134</td> <td>    0.136</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0040</td> <td>    0.000</td> <td>   -9.471</td> <td> 0.000</td> <td>   -0.005</td> <td>   -0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0279</td> <td>    0.000</td> <td>   61.646</td> <td> 0.000</td> <td>    0.027</td> <td>    0.029</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.1062</td> <td>    0.001</td> <td> -197.456</td> <td> 0.000</td> <td>   -0.107</td> <td>   -0.105</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>    0.0350</td> <td>    0.000</td> <td>   71.180</td> <td> 0.000</td> <td>    0.034</td> <td>    0.036</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>    0.0259</td> <td>    0.000</td> <td>   59.319</td> <td> 0.000</td> <td>    0.025</td> <td>    0.027</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0411</td> <td>    0.001</td> <td>   80.905</td> <td> 0.000</td> <td>    0.040</td> <td>    0.042</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>    0.0073</td> <td>    0.000</td> <td>   16.764</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>    0.0061</td> <td>    0.000</td> <td>   14.048</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>4795.339</td> <th>  Durbin-Watson:     </th> <td>   1.990</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>19490.754</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td> 0.094</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td> 5.331</td>  <th>  Cond. No.          </th> <td>    2.77</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      energy      & \\textbf{  R-squared:         } &     0.766   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.766   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } & 1.999e+04   \\\\\n\\textbf{Date:}             & Sat, 21 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}             &     17:46:01     & \\textbf{  Log-Likelihood:    } &    58684.   \\\\\n\\textbf{No. Observations:} &       85500      & \\textbf{  AIC:               } & -1.173e+05  \\\\\n\\textbf{Df Residuals:}     &       85485      & \\textbf{  BIC:               } & -1.172e+05  \\\\\n\\textbf{Df Model:}         &          14      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       0.6420  &        0.000     &  1540.996  &         0.000        &        0.641    &        0.643     \\\\\n\\textbf{x1}    &      -0.0021  &        0.000     &    -4.990  &         0.000        &       -0.003    &       -0.001     \\\\\n\\textbf{x2}    &       0.0048  &        0.000     &    11.313  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x3}    &      -0.0018  &        0.000     &    -4.100  &         0.000        &       -0.003    &       -0.001     \\\\\n\\textbf{x4}    &      -0.0326  &        0.001     &   -64.317  &         0.000        &       -0.034    &       -0.032     \\\\\n\\textbf{x5}    &       0.0013  &        0.000     &     3.002  &         0.003        &        0.000    &        0.002     \\\\\n\\textbf{x6}    &       0.1352  &        0.001     &   226.522  &         0.000        &        0.134    &        0.136     \\\\\n\\textbf{x7}    &      -0.0040  &        0.000     &    -9.471  &         0.000        &       -0.005    &       -0.003     \\\\\n\\textbf{x8}    &       0.0279  &        0.000     &    61.646  &         0.000        &        0.027    &        0.029     \\\\\n\\textbf{x9}    &      -0.1062  &        0.001     &  -197.456  &         0.000        &       -0.107    &       -0.105     \\\\\n\\textbf{x10}   &       0.0350  &        0.000     &    71.180  &         0.000        &        0.034    &        0.036     \\\\\n\\textbf{x11}   &       0.0259  &        0.000     &    59.319  &         0.000        &        0.025    &        0.027     \\\\\n\\textbf{x12}   &       0.0411  &        0.001     &    80.905  &         0.000        &        0.040    &        0.042     \\\\\n\\textbf{x13}   &       0.0073  &        0.000     &    16.764  &         0.000        &        0.006    &        0.008     \\\\\n\\textbf{x14}   &       0.0061  &        0.000     &    14.048  &         0.000        &        0.005    &        0.007     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 4795.339 & \\textbf{  Durbin-Watson:     } &     1.990  \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 19490.754  \\\\\n\\textbf{Skew:}          &   0.094  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n\\textbf{Kurtosis:}      &   5.331  & \\textbf{  Cond. No.          } &      2.77  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "model_sm.summary()\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из результата регрессии с использованием модели OLS  можно извлечь следующую инфу:\n",
        "\n",
        "1. R-squared (R2): значение R2 равно 0.766, модель объясняет около 76.6% вариации в зависимой переменной. Это может считаться относительно хорошим результатом.\n",
        "\n",
        "2. Коэффициенты (coef): для каждой независимой переменной (x1 - x14) приведены соответствующие коэффициенты. Они определяют веса, с которыми каждая независимая переменная входит в модель. Например, коэффициент для x1 равен -0.0021, что указывает на отрицательную связь между x1 и зависимой переменной.\n",
        "\n",
        "3. P-значения (P>|t|): все коэффициенты имеют P-значения, близкие к нулю (P < 0.05), что указывает на их статистическую значимость.\n",
        "\n",
        "4. Доверительные интервалы [0.025 0.975]: данные нам интервалы указывают на диапазон значений, в пределах которого с высокой вероятностью находится реальное значение коэффициента(привет от теорвера).\n",
        "\n",
        "5. Omnibus и Jarque-Bera: при p-значенияч этих тестов меньших уровня значимости, это может указывать на то, что остатки не распределены нормально.\n",
        "\n",
        "6. Durbin-Watson: значение близкое к 2 указывает на отсутствие корреляции остатков.\n",
        "\n",
        "7. Количество наблюдений и степени свободы (Df Residuals и Df Model): значения указывают на количество наблюдений 85372 и степени свободы 127 в модели.\n",
        "\n",
        "В данном случае, F-статистика имеет высокое значение, а вероятность F-статистики близка к нулю, что указывает на общую значимость модели, в целом модель является статистически значимой.\n"
      ],
      "metadata": {
        "id": "IthKm7COpAA4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_sm1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "elunvY5CjBDq",
        "outputId": "f65a895d-e45e-4c5e-bd55-a5fa77a74e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<class 'statsmodels.iolib.summary.Summary'>\n",
              "\"\"\"\n",
              "                            OLS Regression Results                            \n",
              "==============================================================================\n",
              "Dep. Variable:                 energy   R-squared:                       0.801\n",
              "Model:                            OLS   Adj. R-squared:                  0.801\n",
              "Method:                 Least Squares   F-statistic:                     2713.\n",
              "Date:                Sat, 21 Oct 2023   Prob (F-statistic):               0.00\n",
              "Time:                        17:46:05   Log-Likelihood:                 65695.\n",
              "No. Observations:               85500   AIC:                        -1.311e+05\n",
              "Df Residuals:                   85372   BIC:                        -1.299e+05\n",
              "Df Model:                         127                                         \n",
              "Covariance Type:            nonrobust                                         \n",
              "==============================================================================\n",
              "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
              "------------------------------------------------------------------------------\n",
              "const          0.6420      0.000   1671.574      0.000       0.641       0.643\n",
              "x1            -0.0032      0.000     -7.070      0.000      -0.004      -0.002\n",
              "x2             0.0015      0.000      3.406      0.001       0.001       0.002\n",
              "x3            -0.0027      0.000     -6.183      0.000      -0.003      -0.002\n",
              "x4            -0.0198      0.001    -34.664      0.000      -0.021      -0.019\n",
              "x5             0.0012      0.000      2.974      0.003       0.000       0.002\n",
              "x6             0.1356      0.001    222.325      0.000       0.134       0.137\n",
              "x7            -0.0028      0.000     -7.032      0.000      -0.004      -0.002\n",
              "x8             0.0222      0.001     41.977      0.000       0.021       0.023\n",
              "x9            -0.0828      0.001   -137.402      0.000      -0.084      -0.082\n",
              "x10            0.0243      0.001     43.930      0.000       0.023       0.025\n",
              "x11            0.0202      0.000     47.469      0.000       0.019       0.021\n",
              "x12            0.0410      0.001     78.715      0.000       0.040       0.042\n",
              "x13            0.0070      0.000     17.033      0.000       0.006       0.008\n",
              "x14            0.0080      0.000     19.906      0.000       0.007       0.009\n",
              "x15            0.0081      0.001     14.626      0.000       0.007       0.009\n",
              "x16            0.0088      0.001     16.003      0.000       0.008       0.010\n",
              "x17            0.0059      0.001     10.724      0.000       0.005       0.007\n",
              "x18            0.0072      0.001     12.940      0.000       0.006       0.008\n",
              "x19            0.0079      0.001     14.444      0.000       0.007       0.009\n",
              "x20            0.0172      0.001     30.434      0.000       0.016       0.018\n",
              "x21            0.0048      0.001      8.932      0.000       0.004       0.006\n",
              "x22            0.0047      0.001      8.726      0.000       0.004       0.006\n",
              "x23            0.0043      0.001      7.895      0.000       0.003       0.005\n",
              "x24            0.0136      0.001     24.411      0.000       0.013       0.015\n",
              "x25            0.0040      0.001      7.446      0.000       0.003       0.005\n",
              "x26            0.0023      0.001      4.177      0.000       0.001       0.003\n",
              "x27            0.0099      0.001     17.696      0.000       0.009       0.011\n",
              "x28            0.0001      0.001      0.193      0.847      -0.001       0.001\n",
              "x29            0.0002      0.001      0.314      0.754      -0.001       0.001\n",
              "x30            0.0064      0.001     11.438      0.000       0.005       0.007\n",
              "x31            0.0084      0.001     15.227      0.000       0.007       0.009\n",
              "x32            0.0136      0.001     21.212      0.000       0.012       0.015\n",
              "x33            0.0021      0.001      3.819      0.000       0.001       0.003\n",
              "x34            0.0035      0.001      6.443      0.000       0.002       0.005\n",
              "x35            0.0030      0.001      5.391      0.000       0.002       0.004\n",
              "x36            0.0195      0.001     35.025      0.000       0.018       0.021\n",
              "x37            0.0103      0.001     18.932      0.000       0.009       0.011\n",
              "x38            0.0129      0.001     22.738      0.000       0.012       0.014\n",
              "x39            0.0103      0.001     18.689      0.000       0.009       0.011\n",
              "x40            0.0025      0.001      4.629      0.000       0.001       0.004\n",
              "x41            0.0113      0.001     20.362      0.000       0.010       0.012\n",
              "x42            0.0062      0.001     11.350      0.000       0.005       0.007\n",
              "x43            0.0081      0.001     14.926      0.000       0.007       0.009\n",
              "x44            0.0081      0.001     14.949      0.000       0.007       0.009\n",
              "x45            0.0043      0.001      7.887      0.000       0.003       0.005\n",
              "x46            0.0081      0.001     14.703      0.000       0.007       0.009\n",
              "x47            0.0056      0.001     10.215      0.000       0.004       0.007\n",
              "x48            0.0059      0.001     10.950      0.000       0.005       0.007\n",
              "x49            0.0123      0.001     22.685      0.000       0.011       0.013\n",
              "x50            0.0068      0.001     12.397      0.000       0.006       0.008\n",
              "x51            0.0011      0.001      2.041      0.041    4.43e-05       0.002\n",
              "x52            0.0080      0.001     14.727      0.000       0.007       0.009\n",
              "x53            0.0064      0.001     11.714      0.000       0.005       0.007\n",
              "x54            0.0022      0.001      4.055      0.000       0.001       0.003\n",
              "x55            0.0099      0.001     18.161      0.000       0.009       0.011\n",
              "x56            0.0176      0.001     31.177      0.000       0.017       0.019\n",
              "x57            0.0107      0.001     19.665      0.000       0.010       0.012\n",
              "x58            0.0111      0.001     20.267      0.000       0.010       0.012\n",
              "x59            0.0023      0.001      4.147      0.000       0.001       0.003\n",
              "x60            0.0180      0.001     32.594      0.000       0.017       0.019\n",
              "x61            0.0124      0.001     22.584      0.000       0.011       0.013\n",
              "x62            0.0125      0.001     22.911      0.000       0.011       0.014\n",
              "x63            0.0162      0.001     29.226      0.000       0.015       0.017\n",
              "x64            0.0155      0.001     28.146      0.000       0.014       0.017\n",
              "x65            0.0037      0.001      6.760      0.000       0.003       0.005\n",
              "x66           -0.0005      0.001     -0.872      0.383      -0.002       0.001\n",
              "x67            0.0076      0.001     13.939      0.000       0.007       0.009\n",
              "x68            0.0098      0.001     17.661      0.000       0.009       0.011\n",
              "x69            0.0082      0.001     15.145      0.000       0.007       0.009\n",
              "x70            0.0034      0.001      6.278      0.000       0.002       0.004\n",
              "x71            0.0031      0.001      5.661      0.000       0.002       0.004\n",
              "x72            0.0156      0.001     28.308      0.000       0.015       0.017\n",
              "x73            0.0114      0.001     20.378      0.000       0.010       0.012\n",
              "x74            0.0045      0.001      8.020      0.000       0.003       0.006\n",
              "x75            0.0121      0.001     22.084      0.000       0.011       0.013\n",
              "x76            0.0056      0.001     10.350      0.000       0.005       0.007\n",
              "x77            0.0084      0.001     15.473      0.000       0.007       0.010\n",
              "x78           -0.0012      0.001     -2.147      0.032      -0.002      -0.000\n",
              "x79            0.0064      0.001     11.910      0.000       0.005       0.007\n",
              "x80            0.0018      0.001      3.299      0.001       0.001       0.003\n",
              "x81            0.0050      0.001      9.068      0.000       0.004       0.006\n",
              "x82            0.0055      0.001      9.918      0.000       0.004       0.007\n",
              "x83            0.0056      0.001     10.292      0.000       0.005       0.007\n",
              "x84            0.0019      0.001      3.446      0.001       0.001       0.003\n",
              "x85            0.0135      0.001     24.443      0.000       0.012       0.015\n",
              "x86            0.0170      0.001     30.726      0.000       0.016       0.018\n",
              "x87            0.0104      0.001     18.464      0.000       0.009       0.012\n",
              "x88            0.0053      0.001      9.833      0.000       0.004       0.006\n",
              "x89            0.0045      0.001      8.160      0.000       0.003       0.006\n",
              "x90            0.0037      0.001      6.799      0.000       0.003       0.005\n",
              "x91            0.0121      0.001     22.094      0.000       0.011       0.013\n",
              "x92            0.0118      0.001     21.499      0.000       0.011       0.013\n",
              "x93            0.0088      0.001     16.241      0.000       0.008       0.010\n",
              "x94            0.0035      0.001      6.380      0.000       0.002       0.005\n",
              "x95            0.0078      0.001     14.334      0.000       0.007       0.009\n",
              "x96            0.0108      0.001     19.724      0.000       0.010       0.012\n",
              "x97            0.0124      0.001     22.719      0.000       0.011       0.013\n",
              "x98            0.0037      0.001      6.784      0.000       0.003       0.005\n",
              "x99            0.0109      0.001     19.978      0.000       0.010       0.012\n",
              "x100           0.0106      0.001     19.524      0.000       0.010       0.012\n",
              "x101           0.0059      0.001     10.763      0.000       0.005       0.007\n",
              "x102           0.0039      0.001      7.168      0.000       0.003       0.005\n",
              "x103           0.0048      0.001      8.815      0.000       0.004       0.006\n",
              "x104           0.0047      0.001      8.622      0.000       0.004       0.006\n",
              "x105           0.0037      0.001      6.854      0.000       0.003       0.005\n",
              "x106           0.0094      0.001     17.394      0.000       0.008       0.011\n",
              "x107           0.0013      0.001      2.409      0.016       0.000       0.002\n",
              "x108           0.0016      0.001      2.897      0.004       0.001       0.003\n",
              "x109           0.0131      0.001     23.797      0.000       0.012       0.014\n",
              "x110           0.0104      0.001     19.145      0.000       0.009       0.011\n",
              "x111           0.0068      0.001     12.340      0.000       0.006       0.008\n",
              "x112          -0.0006      0.001     -1.162      0.245      -0.002       0.000\n",
              "x113           0.0009      0.001      1.688      0.091      -0.000       0.002\n",
              "x114           0.0098      0.001     17.797      0.000       0.009       0.011\n",
              "x115           0.0261      0.001     44.781      0.000       0.025       0.027\n",
              "x116           0.0005      0.001      0.994      0.320      -0.001       0.002\n",
              "x117           0.0009      0.001      1.621      0.105      -0.000       0.002\n",
              "x118           0.0082      0.001     15.035      0.000       0.007       0.009\n",
              "x119          -0.0048      0.001     -8.586      0.000      -0.006      -0.004\n",
              "x120           0.0056      0.001     10.246      0.000       0.004       0.007\n",
              "x121           0.0103      0.001     18.998      0.000       0.009       0.011\n",
              "x122          -0.0027      0.001     -4.984      0.000      -0.004      -0.002\n",
              "x123           0.0128      0.001     23.003      0.000       0.012       0.014\n",
              "x124           0.0154      0.001     28.021      0.000       0.014       0.017\n",
              "x125           0.0049      0.001      9.018      0.000       0.004       0.006\n",
              "x126           0.0056      0.001     10.303      0.000       0.005       0.007\n",
              "x127           0.0023      0.001      4.259      0.000       0.001       0.003\n",
              "==============================================================================\n",
              "Omnibus:                     5024.938   Durbin-Watson:                   1.995\n",
              "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            20987.131\n",
              "Skew:                          -0.111   Prob(JB):                         0.00\n",
              "Kurtosis:                       5.417   Cond. No.                         18.6\n",
              "==============================================================================\n",
              "\n",
              "Notes:\n",
              "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
              "\"\"\""
            ],
            "text/html": [
              "<table class=\"simpletable\">\n",
              "<caption>OLS Regression Results</caption>\n",
              "<tr>\n",
              "  <th>Dep. Variable:</th>         <td>energy</td>      <th>  R-squared:         </th>  <td>   0.801</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.801</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   2713.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Date:</th>             <td>Sat, 21 Oct 2023</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Time:</th>                 <td>17:46:05</td>     <th>  Log-Likelihood:    </th>  <td>  65695.</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>No. Observations:</th>      <td> 85500</td>      <th>  AIC:               </th> <td>-1.311e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Residuals:</th>          <td> 85372</td>      <th>  BIC:               </th> <td>-1.299e+05</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Df Model:</th>              <td>   127</td>      <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>    \n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>const</th> <td>    0.6420</td> <td>    0.000</td> <td> 1671.574</td> <td> 0.000</td> <td>    0.641</td> <td>    0.643</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x1</th>    <td>   -0.0032</td> <td>    0.000</td> <td>   -7.070</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x2</th>    <td>    0.0015</td> <td>    0.000</td> <td>    3.406</td> <td> 0.001</td> <td>    0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x3</th>    <td>   -0.0027</td> <td>    0.000</td> <td>   -6.183</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x4</th>    <td>   -0.0198</td> <td>    0.001</td> <td>  -34.664</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x5</th>    <td>    0.0012</td> <td>    0.000</td> <td>    2.974</td> <td> 0.003</td> <td>    0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x6</th>    <td>    0.1356</td> <td>    0.001</td> <td>  222.325</td> <td> 0.000</td> <td>    0.134</td> <td>    0.137</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x7</th>    <td>   -0.0028</td> <td>    0.000</td> <td>   -7.032</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x8</th>    <td>    0.0222</td> <td>    0.001</td> <td>   41.977</td> <td> 0.000</td> <td>    0.021</td> <td>    0.023</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x9</th>    <td>   -0.0828</td> <td>    0.001</td> <td> -137.402</td> <td> 0.000</td> <td>   -0.084</td> <td>   -0.082</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x10</th>   <td>    0.0243</td> <td>    0.001</td> <td>   43.930</td> <td> 0.000</td> <td>    0.023</td> <td>    0.025</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x11</th>   <td>    0.0202</td> <td>    0.000</td> <td>   47.469</td> <td> 0.000</td> <td>    0.019</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x12</th>   <td>    0.0410</td> <td>    0.001</td> <td>   78.715</td> <td> 0.000</td> <td>    0.040</td> <td>    0.042</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x13</th>   <td>    0.0070</td> <td>    0.000</td> <td>   17.033</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x14</th>   <td>    0.0080</td> <td>    0.000</td> <td>   19.906</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x15</th>   <td>    0.0081</td> <td>    0.001</td> <td>   14.626</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x16</th>   <td>    0.0088</td> <td>    0.001</td> <td>   16.003</td> <td> 0.000</td> <td>    0.008</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x17</th>   <td>    0.0059</td> <td>    0.001</td> <td>   10.724</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x18</th>   <td>    0.0072</td> <td>    0.001</td> <td>   12.940</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x19</th>   <td>    0.0079</td> <td>    0.001</td> <td>   14.444</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x20</th>   <td>    0.0172</td> <td>    0.001</td> <td>   30.434</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x21</th>   <td>    0.0048</td> <td>    0.001</td> <td>    8.932</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x22</th>   <td>    0.0047</td> <td>    0.001</td> <td>    8.726</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x23</th>   <td>    0.0043</td> <td>    0.001</td> <td>    7.895</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x24</th>   <td>    0.0136</td> <td>    0.001</td> <td>   24.411</td> <td> 0.000</td> <td>    0.013</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x25</th>   <td>    0.0040</td> <td>    0.001</td> <td>    7.446</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x26</th>   <td>    0.0023</td> <td>    0.001</td> <td>    4.177</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x27</th>   <td>    0.0099</td> <td>    0.001</td> <td>   17.696</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x28</th>   <td>    0.0001</td> <td>    0.001</td> <td>    0.193</td> <td> 0.847</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x29</th>   <td>    0.0002</td> <td>    0.001</td> <td>    0.314</td> <td> 0.754</td> <td>   -0.001</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x30</th>   <td>    0.0064</td> <td>    0.001</td> <td>   11.438</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x31</th>   <td>    0.0084</td> <td>    0.001</td> <td>   15.227</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x32</th>   <td>    0.0136</td> <td>    0.001</td> <td>   21.212</td> <td> 0.000</td> <td>    0.012</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x33</th>   <td>    0.0021</td> <td>    0.001</td> <td>    3.819</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x34</th>   <td>    0.0035</td> <td>    0.001</td> <td>    6.443</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x35</th>   <td>    0.0030</td> <td>    0.001</td> <td>    5.391</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x36</th>   <td>    0.0195</td> <td>    0.001</td> <td>   35.025</td> <td> 0.000</td> <td>    0.018</td> <td>    0.021</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x37</th>   <td>    0.0103</td> <td>    0.001</td> <td>   18.932</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x38</th>   <td>    0.0129</td> <td>    0.001</td> <td>   22.738</td> <td> 0.000</td> <td>    0.012</td> <td>    0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x39</th>   <td>    0.0103</td> <td>    0.001</td> <td>   18.689</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x40</th>   <td>    0.0025</td> <td>    0.001</td> <td>    4.629</td> <td> 0.000</td> <td>    0.001</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x41</th>   <td>    0.0113</td> <td>    0.001</td> <td>   20.362</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x42</th>   <td>    0.0062</td> <td>    0.001</td> <td>   11.350</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x43</th>   <td>    0.0081</td> <td>    0.001</td> <td>   14.926</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x44</th>   <td>    0.0081</td> <td>    0.001</td> <td>   14.949</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x45</th>   <td>    0.0043</td> <td>    0.001</td> <td>    7.887</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x46</th>   <td>    0.0081</td> <td>    0.001</td> <td>   14.703</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x47</th>   <td>    0.0056</td> <td>    0.001</td> <td>   10.215</td> <td> 0.000</td> <td>    0.004</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x48</th>   <td>    0.0059</td> <td>    0.001</td> <td>   10.950</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x49</th>   <td>    0.0123</td> <td>    0.001</td> <td>   22.685</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x50</th>   <td>    0.0068</td> <td>    0.001</td> <td>   12.397</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x51</th>   <td>    0.0011</td> <td>    0.001</td> <td>    2.041</td> <td> 0.041</td> <td> 4.43e-05</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x52</th>   <td>    0.0080</td> <td>    0.001</td> <td>   14.727</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x53</th>   <td>    0.0064</td> <td>    0.001</td> <td>   11.714</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x54</th>   <td>    0.0022</td> <td>    0.001</td> <td>    4.055</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x55</th>   <td>    0.0099</td> <td>    0.001</td> <td>   18.161</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x56</th>   <td>    0.0176</td> <td>    0.001</td> <td>   31.177</td> <td> 0.000</td> <td>    0.017</td> <td>    0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x57</th>   <td>    0.0107</td> <td>    0.001</td> <td>   19.665</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x58</th>   <td>    0.0111</td> <td>    0.001</td> <td>   20.267</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x59</th>   <td>    0.0023</td> <td>    0.001</td> <td>    4.147</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x60</th>   <td>    0.0180</td> <td>    0.001</td> <td>   32.594</td> <td> 0.000</td> <td>    0.017</td> <td>    0.019</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x61</th>   <td>    0.0124</td> <td>    0.001</td> <td>   22.584</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x62</th>   <td>    0.0125</td> <td>    0.001</td> <td>   22.911</td> <td> 0.000</td> <td>    0.011</td> <td>    0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x63</th>   <td>    0.0162</td> <td>    0.001</td> <td>   29.226</td> <td> 0.000</td> <td>    0.015</td> <td>    0.017</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x64</th>   <td>    0.0155</td> <td>    0.001</td> <td>   28.146</td> <td> 0.000</td> <td>    0.014</td> <td>    0.017</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x65</th>   <td>    0.0037</td> <td>    0.001</td> <td>    6.760</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x66</th>   <td>   -0.0005</td> <td>    0.001</td> <td>   -0.872</td> <td> 0.383</td> <td>   -0.002</td> <td>    0.001</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x67</th>   <td>    0.0076</td> <td>    0.001</td> <td>   13.939</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x68</th>   <td>    0.0098</td> <td>    0.001</td> <td>   17.661</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x69</th>   <td>    0.0082</td> <td>    0.001</td> <td>   15.145</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x70</th>   <td>    0.0034</td> <td>    0.001</td> <td>    6.278</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x71</th>   <td>    0.0031</td> <td>    0.001</td> <td>    5.661</td> <td> 0.000</td> <td>    0.002</td> <td>    0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x72</th>   <td>    0.0156</td> <td>    0.001</td> <td>   28.308</td> <td> 0.000</td> <td>    0.015</td> <td>    0.017</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x73</th>   <td>    0.0114</td> <td>    0.001</td> <td>   20.378</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x74</th>   <td>    0.0045</td> <td>    0.001</td> <td>    8.020</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x75</th>   <td>    0.0121</td> <td>    0.001</td> <td>   22.084</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x76</th>   <td>    0.0056</td> <td>    0.001</td> <td>   10.350</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x77</th>   <td>    0.0084</td> <td>    0.001</td> <td>   15.473</td> <td> 0.000</td> <td>    0.007</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x78</th>   <td>   -0.0012</td> <td>    0.001</td> <td>   -2.147</td> <td> 0.032</td> <td>   -0.002</td> <td>   -0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x79</th>   <td>    0.0064</td> <td>    0.001</td> <td>   11.910</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x80</th>   <td>    0.0018</td> <td>    0.001</td> <td>    3.299</td> <td> 0.001</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x81</th>   <td>    0.0050</td> <td>    0.001</td> <td>    9.068</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x82</th>   <td>    0.0055</td> <td>    0.001</td> <td>    9.918</td> <td> 0.000</td> <td>    0.004</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x83</th>   <td>    0.0056</td> <td>    0.001</td> <td>   10.292</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x84</th>   <td>    0.0019</td> <td>    0.001</td> <td>    3.446</td> <td> 0.001</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x85</th>   <td>    0.0135</td> <td>    0.001</td> <td>   24.443</td> <td> 0.000</td> <td>    0.012</td> <td>    0.015</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x86</th>   <td>    0.0170</td> <td>    0.001</td> <td>   30.726</td> <td> 0.000</td> <td>    0.016</td> <td>    0.018</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x87</th>   <td>    0.0104</td> <td>    0.001</td> <td>   18.464</td> <td> 0.000</td> <td>    0.009</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x88</th>   <td>    0.0053</td> <td>    0.001</td> <td>    9.833</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x89</th>   <td>    0.0045</td> <td>    0.001</td> <td>    8.160</td> <td> 0.000</td> <td>    0.003</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x90</th>   <td>    0.0037</td> <td>    0.001</td> <td>    6.799</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x91</th>   <td>    0.0121</td> <td>    0.001</td> <td>   22.094</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x92</th>   <td>    0.0118</td> <td>    0.001</td> <td>   21.499</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x93</th>   <td>    0.0088</td> <td>    0.001</td> <td>   16.241</td> <td> 0.000</td> <td>    0.008</td> <td>    0.010</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x94</th>   <td>    0.0035</td> <td>    0.001</td> <td>    6.380</td> <td> 0.000</td> <td>    0.002</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x95</th>   <td>    0.0078</td> <td>    0.001</td> <td>   14.334</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x96</th>   <td>    0.0108</td> <td>    0.001</td> <td>   19.724</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x97</th>   <td>    0.0124</td> <td>    0.001</td> <td>   22.719</td> <td> 0.000</td> <td>    0.011</td> <td>    0.013</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x98</th>   <td>    0.0037</td> <td>    0.001</td> <td>    6.784</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x99</th>   <td>    0.0109</td> <td>    0.001</td> <td>   19.978</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x100</th>  <td>    0.0106</td> <td>    0.001</td> <td>   19.524</td> <td> 0.000</td> <td>    0.010</td> <td>    0.012</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x101</th>  <td>    0.0059</td> <td>    0.001</td> <td>   10.763</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x102</th>  <td>    0.0039</td> <td>    0.001</td> <td>    7.168</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x103</th>  <td>    0.0048</td> <td>    0.001</td> <td>    8.815</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x104</th>  <td>    0.0047</td> <td>    0.001</td> <td>    8.622</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x105</th>  <td>    0.0037</td> <td>    0.001</td> <td>    6.854</td> <td> 0.000</td> <td>    0.003</td> <td>    0.005</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x106</th>  <td>    0.0094</td> <td>    0.001</td> <td>   17.394</td> <td> 0.000</td> <td>    0.008</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x107</th>  <td>    0.0013</td> <td>    0.001</td> <td>    2.409</td> <td> 0.016</td> <td>    0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x108</th>  <td>    0.0016</td> <td>    0.001</td> <td>    2.897</td> <td> 0.004</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x109</th>  <td>    0.0131</td> <td>    0.001</td> <td>   23.797</td> <td> 0.000</td> <td>    0.012</td> <td>    0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x110</th>  <td>    0.0104</td> <td>    0.001</td> <td>   19.145</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x111</th>  <td>    0.0068</td> <td>    0.001</td> <td>   12.340</td> <td> 0.000</td> <td>    0.006</td> <td>    0.008</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x112</th>  <td>   -0.0006</td> <td>    0.001</td> <td>   -1.162</td> <td> 0.245</td> <td>   -0.002</td> <td>    0.000</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x113</th>  <td>    0.0009</td> <td>    0.001</td> <td>    1.688</td> <td> 0.091</td> <td>   -0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x114</th>  <td>    0.0098</td> <td>    0.001</td> <td>   17.797</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x115</th>  <td>    0.0261</td> <td>    0.001</td> <td>   44.781</td> <td> 0.000</td> <td>    0.025</td> <td>    0.027</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x116</th>  <td>    0.0005</td> <td>    0.001</td> <td>    0.994</td> <td> 0.320</td> <td>   -0.001</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x117</th>  <td>    0.0009</td> <td>    0.001</td> <td>    1.621</td> <td> 0.105</td> <td>   -0.000</td> <td>    0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x118</th>  <td>    0.0082</td> <td>    0.001</td> <td>   15.035</td> <td> 0.000</td> <td>    0.007</td> <td>    0.009</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x119</th>  <td>   -0.0048</td> <td>    0.001</td> <td>   -8.586</td> <td> 0.000</td> <td>   -0.006</td> <td>   -0.004</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x120</th>  <td>    0.0056</td> <td>    0.001</td> <td>   10.246</td> <td> 0.000</td> <td>    0.004</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x121</th>  <td>    0.0103</td> <td>    0.001</td> <td>   18.998</td> <td> 0.000</td> <td>    0.009</td> <td>    0.011</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x122</th>  <td>   -0.0027</td> <td>    0.001</td> <td>   -4.984</td> <td> 0.000</td> <td>   -0.004</td> <td>   -0.002</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x123</th>  <td>    0.0128</td> <td>    0.001</td> <td>   23.003</td> <td> 0.000</td> <td>    0.012</td> <td>    0.014</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x124</th>  <td>    0.0154</td> <td>    0.001</td> <td>   28.021</td> <td> 0.000</td> <td>    0.014</td> <td>    0.017</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x125</th>  <td>    0.0049</td> <td>    0.001</td> <td>    9.018</td> <td> 0.000</td> <td>    0.004</td> <td>    0.006</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x126</th>  <td>    0.0056</td> <td>    0.001</td> <td>   10.303</td> <td> 0.000</td> <td>    0.005</td> <td>    0.007</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>x127</th>  <td>    0.0023</td> <td>    0.001</td> <td>    4.259</td> <td> 0.000</td> <td>    0.001</td> <td>    0.003</td>\n",
              "</tr>\n",
              "</table>\n",
              "<table class=\"simpletable\">\n",
              "<tr>\n",
              "  <th>Omnibus:</th>       <td>5024.938</td> <th>  Durbin-Watson:     </th> <td>   1.995</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>20987.131</td>\n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Skew:</th>           <td>-0.111</td>  <th>  Prob(JB):          </th> <td>    0.00</td> \n",
              "</tr>\n",
              "<tr>\n",
              "  <th>Kurtosis:</th>       <td> 5.417</td>  <th>  Cond. No.          </th> <td>    18.6</td> \n",
              "</tr>\n",
              "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
            ],
            "text/latex": "\\begin{center}\n\\begin{tabular}{lclc}\n\\toprule\n\\textbf{Dep. Variable:}    &      energy      & \\textbf{  R-squared:         } &     0.801   \\\\\n\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.801   \\\\\n\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     2713.   \\\\\n\\textbf{Date:}             & Sat, 21 Oct 2023 & \\textbf{  Prob (F-statistic):} &     0.00    \\\\\n\\textbf{Time:}             &     17:46:05     & \\textbf{  Log-Likelihood:    } &    65695.   \\\\\n\\textbf{No. Observations:} &       85500      & \\textbf{  AIC:               } & -1.311e+05  \\\\\n\\textbf{Df Residuals:}     &       85372      & \\textbf{  BIC:               } & -1.299e+05  \\\\\n\\textbf{Df Model:}         &         127      & \\textbf{                     } &             \\\\\n\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lcccccc}\n               & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n\\midrule\n\\textbf{const} &       0.6420  &        0.000     &  1671.574  &         0.000        &        0.641    &        0.643     \\\\\n\\textbf{x1}    &      -0.0032  &        0.000     &    -7.070  &         0.000        &       -0.004    &       -0.002     \\\\\n\\textbf{x2}    &       0.0015  &        0.000     &     3.406  &         0.001        &        0.001    &        0.002     \\\\\n\\textbf{x3}    &      -0.0027  &        0.000     &    -6.183  &         0.000        &       -0.003    &       -0.002     \\\\\n\\textbf{x4}    &      -0.0198  &        0.001     &   -34.664  &         0.000        &       -0.021    &       -0.019     \\\\\n\\textbf{x5}    &       0.0012  &        0.000     &     2.974  &         0.003        &        0.000    &        0.002     \\\\\n\\textbf{x6}    &       0.1356  &        0.001     &   222.325  &         0.000        &        0.134    &        0.137     \\\\\n\\textbf{x7}    &      -0.0028  &        0.000     &    -7.032  &         0.000        &       -0.004    &       -0.002     \\\\\n\\textbf{x8}    &       0.0222  &        0.001     &    41.977  &         0.000        &        0.021    &        0.023     \\\\\n\\textbf{x9}    &      -0.0828  &        0.001     &  -137.402  &         0.000        &       -0.084    &       -0.082     \\\\\n\\textbf{x10}   &       0.0243  &        0.001     &    43.930  &         0.000        &        0.023    &        0.025     \\\\\n\\textbf{x11}   &       0.0202  &        0.000     &    47.469  &         0.000        &        0.019    &        0.021     \\\\\n\\textbf{x12}   &       0.0410  &        0.001     &    78.715  &         0.000        &        0.040    &        0.042     \\\\\n\\textbf{x13}   &       0.0070  &        0.000     &    17.033  &         0.000        &        0.006    &        0.008     \\\\\n\\textbf{x14}   &       0.0080  &        0.000     &    19.906  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x15}   &       0.0081  &        0.001     &    14.626  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x16}   &       0.0088  &        0.001     &    16.003  &         0.000        &        0.008    &        0.010     \\\\\n\\textbf{x17}   &       0.0059  &        0.001     &    10.724  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x18}   &       0.0072  &        0.001     &    12.940  &         0.000        &        0.006    &        0.008     \\\\\n\\textbf{x19}   &       0.0079  &        0.001     &    14.444  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x20}   &       0.0172  &        0.001     &    30.434  &         0.000        &        0.016    &        0.018     \\\\\n\\textbf{x21}   &       0.0048  &        0.001     &     8.932  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x22}   &       0.0047  &        0.001     &     8.726  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x23}   &       0.0043  &        0.001     &     7.895  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x24}   &       0.0136  &        0.001     &    24.411  &         0.000        &        0.013    &        0.015     \\\\\n\\textbf{x25}   &       0.0040  &        0.001     &     7.446  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x26}   &       0.0023  &        0.001     &     4.177  &         0.000        &        0.001    &        0.003     \\\\\n\\textbf{x27}   &       0.0099  &        0.001     &    17.696  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x28}   &       0.0001  &        0.001     &     0.193  &         0.847        &       -0.001    &        0.001     \\\\\n\\textbf{x29}   &       0.0002  &        0.001     &     0.314  &         0.754        &       -0.001    &        0.001     \\\\\n\\textbf{x30}   &       0.0064  &        0.001     &    11.438  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x31}   &       0.0084  &        0.001     &    15.227  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x32}   &       0.0136  &        0.001     &    21.212  &         0.000        &        0.012    &        0.015     \\\\\n\\textbf{x33}   &       0.0021  &        0.001     &     3.819  &         0.000        &        0.001    &        0.003     \\\\\n\\textbf{x34}   &       0.0035  &        0.001     &     6.443  &         0.000        &        0.002    &        0.005     \\\\\n\\textbf{x35}   &       0.0030  &        0.001     &     5.391  &         0.000        &        0.002    &        0.004     \\\\\n\\textbf{x36}   &       0.0195  &        0.001     &    35.025  &         0.000        &        0.018    &        0.021     \\\\\n\\textbf{x37}   &       0.0103  &        0.001     &    18.932  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x38}   &       0.0129  &        0.001     &    22.738  &         0.000        &        0.012    &        0.014     \\\\\n\\textbf{x39}   &       0.0103  &        0.001     &    18.689  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x40}   &       0.0025  &        0.001     &     4.629  &         0.000        &        0.001    &        0.004     \\\\\n\\textbf{x41}   &       0.0113  &        0.001     &    20.362  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x42}   &       0.0062  &        0.001     &    11.350  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x43}   &       0.0081  &        0.001     &    14.926  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x44}   &       0.0081  &        0.001     &    14.949  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x45}   &       0.0043  &        0.001     &     7.887  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x46}   &       0.0081  &        0.001     &    14.703  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x47}   &       0.0056  &        0.001     &    10.215  &         0.000        &        0.004    &        0.007     \\\\\n\\textbf{x48}   &       0.0059  &        0.001     &    10.950  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x49}   &       0.0123  &        0.001     &    22.685  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x50}   &       0.0068  &        0.001     &    12.397  &         0.000        &        0.006    &        0.008     \\\\\n\\textbf{x51}   &       0.0011  &        0.001     &     2.041  &         0.041        &     4.43e-05    &        0.002     \\\\\n\\textbf{x52}   &       0.0080  &        0.001     &    14.727  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x53}   &       0.0064  &        0.001     &    11.714  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x54}   &       0.0022  &        0.001     &     4.055  &         0.000        &        0.001    &        0.003     \\\\\n\\textbf{x55}   &       0.0099  &        0.001     &    18.161  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x56}   &       0.0176  &        0.001     &    31.177  &         0.000        &        0.017    &        0.019     \\\\\n\\textbf{x57}   &       0.0107  &        0.001     &    19.665  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x58}   &       0.0111  &        0.001     &    20.267  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x59}   &       0.0023  &        0.001     &     4.147  &         0.000        &        0.001    &        0.003     \\\\\n\\textbf{x60}   &       0.0180  &        0.001     &    32.594  &         0.000        &        0.017    &        0.019     \\\\\n\\textbf{x61}   &       0.0124  &        0.001     &    22.584  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x62}   &       0.0125  &        0.001     &    22.911  &         0.000        &        0.011    &        0.014     \\\\\n\\textbf{x63}   &       0.0162  &        0.001     &    29.226  &         0.000        &        0.015    &        0.017     \\\\\n\\textbf{x64}   &       0.0155  &        0.001     &    28.146  &         0.000        &        0.014    &        0.017     \\\\\n\\textbf{x65}   &       0.0037  &        0.001     &     6.760  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x66}   &      -0.0005  &        0.001     &    -0.872  &         0.383        &       -0.002    &        0.001     \\\\\n\\textbf{x67}   &       0.0076  &        0.001     &    13.939  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x68}   &       0.0098  &        0.001     &    17.661  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x69}   &       0.0082  &        0.001     &    15.145  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x70}   &       0.0034  &        0.001     &     6.278  &         0.000        &        0.002    &        0.004     \\\\\n\\textbf{x71}   &       0.0031  &        0.001     &     5.661  &         0.000        &        0.002    &        0.004     \\\\\n\\textbf{x72}   &       0.0156  &        0.001     &    28.308  &         0.000        &        0.015    &        0.017     \\\\\n\\textbf{x73}   &       0.0114  &        0.001     &    20.378  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x74}   &       0.0045  &        0.001     &     8.020  &         0.000        &        0.003    &        0.006     \\\\\n\\textbf{x75}   &       0.0121  &        0.001     &    22.084  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x76}   &       0.0056  &        0.001     &    10.350  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x77}   &       0.0084  &        0.001     &    15.473  &         0.000        &        0.007    &        0.010     \\\\\n\\textbf{x78}   &      -0.0012  &        0.001     &    -2.147  &         0.032        &       -0.002    &       -0.000     \\\\\n\\textbf{x79}   &       0.0064  &        0.001     &    11.910  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x80}   &       0.0018  &        0.001     &     3.299  &         0.001        &        0.001    &        0.003     \\\\\n\\textbf{x81}   &       0.0050  &        0.001     &     9.068  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x82}   &       0.0055  &        0.001     &     9.918  &         0.000        &        0.004    &        0.007     \\\\\n\\textbf{x83}   &       0.0056  &        0.001     &    10.292  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x84}   &       0.0019  &        0.001     &     3.446  &         0.001        &        0.001    &        0.003     \\\\\n\\textbf{x85}   &       0.0135  &        0.001     &    24.443  &         0.000        &        0.012    &        0.015     \\\\\n\\textbf{x86}   &       0.0170  &        0.001     &    30.726  &         0.000        &        0.016    &        0.018     \\\\\n\\textbf{x87}   &       0.0104  &        0.001     &    18.464  &         0.000        &        0.009    &        0.012     \\\\\n\\textbf{x88}   &       0.0053  &        0.001     &     9.833  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x89}   &       0.0045  &        0.001     &     8.160  &         0.000        &        0.003    &        0.006     \\\\\n\\textbf{x90}   &       0.0037  &        0.001     &     6.799  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x91}   &       0.0121  &        0.001     &    22.094  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x92}   &       0.0118  &        0.001     &    21.499  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x93}   &       0.0088  &        0.001     &    16.241  &         0.000        &        0.008    &        0.010     \\\\\n\\textbf{x94}   &       0.0035  &        0.001     &     6.380  &         0.000        &        0.002    &        0.005     \\\\\n\\textbf{x95}   &       0.0078  &        0.001     &    14.334  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x96}   &       0.0108  &        0.001     &    19.724  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x97}   &       0.0124  &        0.001     &    22.719  &         0.000        &        0.011    &        0.013     \\\\\n\\textbf{x98}   &       0.0037  &        0.001     &     6.784  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x99}   &       0.0109  &        0.001     &    19.978  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x100}  &       0.0106  &        0.001     &    19.524  &         0.000        &        0.010    &        0.012     \\\\\n\\textbf{x101}  &       0.0059  &        0.001     &    10.763  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x102}  &       0.0039  &        0.001     &     7.168  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x103}  &       0.0048  &        0.001     &     8.815  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x104}  &       0.0047  &        0.001     &     8.622  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x105}  &       0.0037  &        0.001     &     6.854  &         0.000        &        0.003    &        0.005     \\\\\n\\textbf{x106}  &       0.0094  &        0.001     &    17.394  &         0.000        &        0.008    &        0.011     \\\\\n\\textbf{x107}  &       0.0013  &        0.001     &     2.409  &         0.016        &        0.000    &        0.002     \\\\\n\\textbf{x108}  &       0.0016  &        0.001     &     2.897  &         0.004        &        0.001    &        0.003     \\\\\n\\textbf{x109}  &       0.0131  &        0.001     &    23.797  &         0.000        &        0.012    &        0.014     \\\\\n\\textbf{x110}  &       0.0104  &        0.001     &    19.145  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x111}  &       0.0068  &        0.001     &    12.340  &         0.000        &        0.006    &        0.008     \\\\\n\\textbf{x112}  &      -0.0006  &        0.001     &    -1.162  &         0.245        &       -0.002    &        0.000     \\\\\n\\textbf{x113}  &       0.0009  &        0.001     &     1.688  &         0.091        &       -0.000    &        0.002     \\\\\n\\textbf{x114}  &       0.0098  &        0.001     &    17.797  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x115}  &       0.0261  &        0.001     &    44.781  &         0.000        &        0.025    &        0.027     \\\\\n\\textbf{x116}  &       0.0005  &        0.001     &     0.994  &         0.320        &       -0.001    &        0.002     \\\\\n\\textbf{x117}  &       0.0009  &        0.001     &     1.621  &         0.105        &       -0.000    &        0.002     \\\\\n\\textbf{x118}  &       0.0082  &        0.001     &    15.035  &         0.000        &        0.007    &        0.009     \\\\\n\\textbf{x119}  &      -0.0048  &        0.001     &    -8.586  &         0.000        &       -0.006    &       -0.004     \\\\\n\\textbf{x120}  &       0.0056  &        0.001     &    10.246  &         0.000        &        0.004    &        0.007     \\\\\n\\textbf{x121}  &       0.0103  &        0.001     &    18.998  &         0.000        &        0.009    &        0.011     \\\\\n\\textbf{x122}  &      -0.0027  &        0.001     &    -4.984  &         0.000        &       -0.004    &       -0.002     \\\\\n\\textbf{x123}  &       0.0128  &        0.001     &    23.003  &         0.000        &        0.012    &        0.014     \\\\\n\\textbf{x124}  &       0.0154  &        0.001     &    28.021  &         0.000        &        0.014    &        0.017     \\\\\n\\textbf{x125}  &       0.0049  &        0.001     &     9.018  &         0.000        &        0.004    &        0.006     \\\\\n\\textbf{x126}  &       0.0056  &        0.001     &    10.303  &         0.000        &        0.005    &        0.007     \\\\\n\\textbf{x127}  &       0.0023  &        0.001     &     4.259  &         0.000        &        0.001    &        0.003     \\\\\n\\bottomrule\n\\end{tabular}\n\\begin{tabular}{lclc}\n\\textbf{Omnibus:}       & 5024.938 & \\textbf{  Durbin-Watson:     } &     1.995  \\\\\n\\textbf{Prob(Omnibus):} &   0.000  & \\textbf{  Jarque-Bera (JB):  } & 20987.131  \\\\\n\\textbf{Skew:}          &  -0.111  & \\textbf{  Prob(JB):          } &      0.00  \\\\\n\\textbf{Kurtosis:}      &   5.417  & \\textbf{  Cond. No.          } &      18.6  \\\\\n\\bottomrule\n\\end{tabular}\n%\\caption{OLS Regression Results}\n\\end{center}\n\nNotes: \\newline\n [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из результатов регрессии с использованием модели OLS можно извлечь следующую инфу:\n",
        "\n",
        "1. R-squared (R2): значение R2 равно 0.801, что означает, что модель объясняет около 80.1% вариации в зависимой переменной energy.\n",
        "\n",
        "2. Коэффициенты (coef): для каждой из 127 независимых переменных (x1 - x127) приведены соответствующие коэффициенты. Они определяют веса, с которыми каждая переменная влияет на зависимую переменную. значительная часть переменных имеют положительные коэффициенты, что указывает на положительную связь с зависимой переменной energy.\n",
        "\n",
        "3. P-значения (P>|t|): почти все коэффициенты имеют P-значения, близкие к нулю (P < 0.05), что указывает на их статистическую значимость. Только несколько переменных имеют P-значения, превышающие уровень значимости 0.05.\n",
        "\n",
        "4. Доверительные интервалы [0.025 0.975]: доверительные интервалы указывают на диапазон значений, в пределах которого с вероятностью находится реальное значение коэффициента.(все то же самое с прошлого обоснвоания)\n",
        "\n",
        "5. Общая значимость модели: F-статистика имеет высокое значение, а вероятность F-статистики близка к нулю. это указывает на общую значимость модели, исходя из множества независимых переменных.\n",
        "\n",
        "6. Omnibus и Jarque-Bera: тут p-значения обеих статистик близки к нулю, а это может указывать в свое время на отклонение от нормального распределения остатков.\n",
        "\n",
        "7. Durbin-Watson: значение близко к 2, что указывает на отсутствие корреляции остатков.( все то же самое с прошлого обоснования и выводов)\n",
        "\n",
        "8. Количество наблюдений и степени свободы: наблюдений 85500, степеней свободы в модели 127.\n",
        "\n",
        "Касательно значимости коэфф, большинство из них оказались статистически значимыми, а это говорит о важности этих переменных для модели. часть коэфф указывают на направление связи с зависимой переменной. в целом и общем, модель значима и даже показывает более правильные и честные результаты в сравненнии с предыдущей без категориальных\n"
      ],
      "metadata": {
        "id": "piGvdmTjpHGZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLcvGlUZy-Qt"
      },
      "source": [
        "#### 5. [1 балл] Реализуйте один из алгоритмов отбора признаков (Elimination by P-value, Forward elimination, Backward elimination), сделайте выводы.\n",
        "\n",
        "Вывод: с помощью алгоритма отборов признаков мы смогли провести оценку важности. каждого из признаков, постепенно отсекая ненужные. Таким образом, самыми важными и значимыми признаками оказались 'popularity', 'danceability', 'loudness', 'speechiness', 'acousticness', 'valence'\n",
        "\n",
        "Надеюсь, что такого обоснования достаточно\n",
        "\n",
        "Алгоритм работает оч долго, при проверке работал 8 минут, так что прошу прощения(("
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "TnrbRbkwy-Qt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4246d24-e629-4137-83ef-1ee12b4f79cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected Features:\n",
            "['popularity', 'danceability', 'loudness', 'speechiness', 'acousticness', 'valence']\n"
          ]
        }
      ],
      "source": [
        "# your code here\n",
        "X_df_2 = X_df.copy()\n",
        "X_df_2['explicit'] = X_df_2['explicit'].astype(int)\n",
        "y_2 = y.to_numpy()\n",
        "\n",
        "columns = X_df.columns.tolist()\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_df_2)\n",
        "f_X_df = sm.add_constant(X_scaled)\n",
        "\n",
        "# Backward Elimination\n",
        "def backward_elimination(featuresQ, targetQ, sign_level=0.05):\n",
        "    num_features = featuresQ.shape[1]\n",
        "    for i in range(num_features):\n",
        "        model = sm.OLS(targetQ, featuresQ).fit()\n",
        "        max_pvalue = max(model.pvalues)\n",
        "        if max_pvalue > sign_level:\n",
        "            max_pvalue_idx = np.argmax(model.pvalues[1:]) + 1 # Exclude the constant term\n",
        "            # features = featuresQ.delete(featuresQ.columns[max_pvalue_idx], axis=1)\n",
        "            featuresQ = np.delete(featuresQ, max_pvalue_idx, axis=1)\n",
        "            columns.pop(max_pvalue_idx)\n",
        "            # TO_DO: delete columns by max_pvalue_idx\n",
        "        else:\n",
        "            break\n",
        "    return columns\n",
        "\n",
        "selected_features = backward_elimination(X_scaled, y_2)\n",
        "print(\"Selected Features:\")\n",
        "print(selected_features)\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df0eQLdNy-Qt"
      },
      "source": [
        "#### 6. [1 балл] Найдите лучший (по RMSE) $\\alpha$ для регрессиии Lasso, используя кросс-валидацию на 5 фолдов. Вы должны выбрать значение из промежутка $[10^{-4}, 10^{3}]$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JPoT3YHqy-Qt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "7a3a4c7c-c854-49d3-a711-000247e4e57d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'alpha': 0.00030625}"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression RMSE\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0.013570507134759739"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ваш код здесь\n",
        "al_znach = []\n",
        "par = 10**-4\n",
        "while par < 10**3:\n",
        "    al_znach.append(par)\n",
        "    par *= 1.75\n",
        "# Можно сделать 1.1, но лучше из [1.5, 2.5], сделал 1-75 чтоб работало 2 минуты\n",
        "# C 1.1 долго отрабатывала\n",
        "parameters = {\"alpha\":al_znach}\n",
        "lasso_regression = GridSearchCV(Lasso(), parameters, scoring='neg_mean_squared_error', cv=5)\n",
        "lasso_regression.n_splits_=5\n",
        "lasso_regression.fit(X_df, y)\n",
        "# сделали на 5 фолдов, но работает 2 минут из-за par\n",
        "display(lasso_regression.best_params_)\n",
        "regression_rmse = mean_squared_error(y, lasso_regression.predict(X_df))\n",
        "print(\"Regression RMSE\")\n",
        "display(regression_rmse)\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1PKinJUy-Qt"
      },
      "source": [
        "## Градиентный спуск\n",
        "\n",
        "#### 7. [3.5 балла] Имплементируйте  Ridge регрессию для MSE loss, обученную на градиентом спуске.\n",
        "\n",
        "\n",
        "Все вычисления должны быть векторизованы, а циклы Python можно использовать только для итераций градиентного спуска. В качестве критерия остановки необходимо использовать (одновременно):\n",
        "\n",
        "* проверка абсолютной нормы разницы весов на двух соседних итерациях (например, меньше некоторого малого числа порядка $10^{-6}$, заданного параметром `tolerance`);\n",
        "\n",
        "* достижение максимального количества итераций (например, 10000, заданного параметром `max_iter`).\n",
        "\n",
        "Вам необходимо выполнить:\n",
        "\n",
        "* Полный градиентный спуск:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} Q(w_{k}).\n",
        "$$\n",
        "\n",
        "* Стохастический градиентный спуск:\n",
        "\n",
        "$$\n",
        "w_{k + 1} = w_{k} - \\eta_{k} \\nabla_{w} q_{i_{k}}(w_{k}).\n",
        "$$\n",
        "\n",
        "$\\nabla_{w} q_{i_{k}}(w_{k}) \\, $ является оценкой градиента по набору объектов, выбранных случайным образом.\n",
        "\n",
        "* Momentum method:\n",
        "\n",
        "$$\n",
        "h_0 = 0, \\\\\n",
        "h_{k + 1} = \\alpha h_{k} + \\eta_k \\nabla_{w} Q(w_{k}), \\\\\n",
        "w_{k + 1} = w_{k} - h_{k + 1}.\n",
        "$$\n",
        "\n",
        "* Adagrad method:\n",
        "\n",
        "$$\n",
        "G_0 = 0, \\\\\n",
        "G_{k + 1} = G_{k} + (\\nabla_{w} Q(w_{k+1}))^2, \\\\\n",
        "w_{k + 1} = w_{k} - \\eta * \\frac{\\nabla_{w} Q(w_{k+1})}{\\sqrt{G_{k+1} + \\epsilon}}.\n",
        "$$\n",
        "\n",
        "Чтобы убедиться, что процесс оптимизации действительно выполняется, мы будем использовать атрибут класса `loss_history`. После вызова метода fit он должен содержать значения функции потерь для всех итераций, начиная с первой (до первого шага по антиградиенту).\n",
        "\n",
        "\n",
        "Вам нужно инициализировать веса случайным вектором из нормального распределения. Ниже приведен шаблон, который должен содержать код, реализующий все варианты моделей."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator\n",
        "\n",
        "class RidgeGD(BaseEstimator):\n",
        "    def __init__(self, delta=1.0, gd_type='Momentum',\n",
        "                 tolerance=1e-4, max_iter=1000, w0=None, eta=1e-2, alpha=1e-3, reg_cf=1e-3, epsilon=1e-4):\n",
        "        self.delta = delta\n",
        "        self.gd_type = gd_type\n",
        "        self.tolerance = tolerance\n",
        "        self.max_iter = max_iter\n",
        "        self.w0 = w0\n",
        "        self.alpha = alpha\n",
        "        self.w = None\n",
        "        self.eta = eta\n",
        "        self.loss_history = None\n",
        "        self.reg_cf = reg_cf\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        X = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        self.kol_features = X.shape[1]\n",
        "        self.kol_batch = int(np.round(self.kol_features * self.delta))\n",
        "\n",
        "        if self.kol_batch < 1:\n",
        "            self.kol_batch = 1\n",
        "        if self.w0 is None:\n",
        "            mean = y.mean() / X.shape[0]\n",
        "            scale = y.std()\n",
        "            self.w = np.random.normal(mean, scale, size=self.kol_features)\n",
        "            self.w0 = self.w.copy()\n",
        "        else:\n",
        "            self.w = self.w0.copy()\n",
        "        self.loss_history = []\n",
        "        loss = self.calc_loss(X, y)\n",
        "        self.loss_history.append(loss)\n",
        "\n",
        "        # дальше тупо реализуем методы\n",
        "        if self.gd_type == 'GradientDescent':\n",
        "            for it in range(0, self.max_iter):\n",
        "                grad = self.calc_gradient(X, y)\n",
        "                self.w -= self.eta * grad\n",
        "                current_loss = self.calc_loss(X, y)\n",
        "                self.loss_history.append(current_loss)\n",
        "                if np.abs(self.loss_history[-1] - self.loss_history[-2]) < self.tolerance:\n",
        "                    break\n",
        "        elif self.gd_type == 'StohasticDescent':\n",
        "            # да что с ним не так\n",
        "            for it in range(0, self.max_iter):\n",
        "                selected_features = np.random.choice(X.shape[0], size=self.kol_batch, replace=False)\n",
        "                grad__ = self.calc_gradient(X[selected_features], y.to_numpy()[selected_features])\n",
        "                self.w -= self.eta * grad__\n",
        "                current_loss = self.calc_loss(X, y)\n",
        "                self.loss_history.append(current_loss)\n",
        "                if np.abs(self.loss_history[-1] - self.loss_history[-2]) < self.tolerance:\n",
        "                    break\n",
        "            # weights = [w_init]\n",
        "            # w = w_init.copy()\n",
        "            # for i in range(n_iterations):\n",
        "            #     batch_indices = np.random.choice(X.shape[0], size=batch_size, replace=False)\n",
        "            #     X_batch, y_batch = X[batch_indices], y[batch_indices]\n",
        "            #     grad = loss.calc_grad(X_batch, y_batch, w)\n",
        "            #     w = w - lr * grad\n",
        "            #     weights.append(w)\n",
        "            # return weights\n",
        "            # теперь работает, Спасибо Кириллу Валерьевичу aka Darky Dash\n",
        "        elif self.gd_type == 'Momentum':\n",
        "            last_grad = np.zeros(self.kol_features)\n",
        "            for it in range (0, self.max_iter):\n",
        "                grad = self.calc_gradient(X, y)\n",
        "                last_grad *= self.alpha\n",
        "                self.w -= (self.eta * grad + last_grad)\n",
        "                last_grad += grad\n",
        "                current_loss = self.calc_loss(X, y)\n",
        "                self.loss_history.append(current_loss)\n",
        "                if np.abs(self.loss_history[-1] - self.loss_history[-2]) < self.tolerance:\n",
        "                    break\n",
        "        elif self.gd_type == 'Adagrad':\n",
        "            G = np.zeros(self.kol_features)\n",
        "            for it in range(0, self.max_iter):\n",
        "                grad = self.calc_gradient(X, y)\n",
        "                G += grad**2\n",
        "                self.w -= (grad * self.eta) / (G + self.epsilon) ** 0.5\n",
        "                current_loss = self.calc_loss(X, y)\n",
        "                self.loss_history.append(current_loss)\n",
        "                if np.abs(self.loss_history[-1] - self.loss_history[-2]) < self.tolerance:\n",
        "                    break\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        if self.w is None:\n",
        "            raise Exception('Not trained yet')\n",
        "\n",
        "        if X.shape[1] == self.kol_features:\n",
        "            X_new = X\n",
        "        else:\n",
        "            X_new = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "\n",
        "        return (self.w * X_new).sum(axis=(1))\n",
        "\n",
        "    def calc_gradient(self, X, y):\n",
        "        res = X.transpose() @ (X @ self.w - y)\n",
        "        res /= len(y)\n",
        "        res += self.w * self.reg_cf\n",
        "        res *= 2\n",
        "        return res\n",
        "\n",
        "    def calc_loss(self, X, y):\n",
        "        return self._loss(self.predict(X), y)\n",
        "\n",
        "    def _loss(self, y1, y2, reg_cf=None, w=None):\n",
        "        if w is None:\n",
        "            w = self.w\n",
        "        if reg_cf is None:\n",
        "            reg_cf = self.reg_cf\n",
        "        return ((y1 - y2)**2).sum() / len(y1) + (w ** 2 * reg_cf).sum()"
      ],
      "metadata": {
        "id": "baRFQBGO62o7"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QQJEjGVy-Qu"
      },
      "source": [
        "#### 8. [1 балл] Натренируйте и провалидируйте \"ручные\" модели на тех же даннных, сравните качество с моделями из Sklearn и StatsModels. Исследуйте влияние параметров `max_iter` и `alpha` на процесс оптимизации. Соответствует ли оно вашим ожиданиям?\n",
        "\n",
        "Исследование: при увеличении max_iter повышается качество и обучаемость моделей, при этом время тренировки увеличивается и может возникнуть проблема переобучения\n",
        "влияние альфы не явилось значительным фактором обучения, но повлияло на точность значений модели\n",
        "\n",
        "Ответ: с подобранными коэфф-ми и параметром max_iter модели приближенны к реальным значениям полученных из результатов работы с методами библиотеки sсlearn, методы momentum явля-ся более приближенным к реальности, затем градиентный спуск, затем вышел адаград с небольшим разрывом от градиентного, но самой худшей оказался стозастика-градиент\n",
        "\n",
        "но стоит не забывать, что при повторных запусках будут меняться результаты, из-за рандомного подбора и инициализации весов в fit\n",
        "\n",
        "к сожалению, написать иделаьный градиент не получилось, но я рад, что написал стохастику благодаря помощи Полуниной и семера моего"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "rIJNcxt_y-Qu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cd94a6-74fc-4726-afe5-ac571902a749"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RidgeGD (GradientDescent): MSE = 0.01798158094526033, R^2 = 0.7137965497127841, Sklearn Ridge: MSE = 0.012639874734367187\n",
            "RidgeGD (StohasticDescent): MSE = 0.02083349170549255, R^2 = 0.6684041728147536, Sklearn Ridge: MSE = 0.012639874734367187\n",
            "RidgeGD (Momentum): MSE = 0.016344909612927297, R^2 = 0.7398465941291152, Sklearn Ridge: MSE = 0.012639874734367187\n",
            "RidgeGD (Adagrad): MSE = 0.017512238280685963, R^2 = 0.7212668322411724, Sklearn Ridge: MSE = 0.012639874734367187\n"
          ]
        }
      ],
      "source": [
        "# код здесь\n",
        "models = [\n",
        "    RidgeGD(gd_type='GradientDescent', max_iter=1000, alpha=0.01),\n",
        "    RidgeGD(gd_type='StohasticDescent', max_iter=1000, eta=0.01),\n",
        "    RidgeGD(gd_type='Momentum', max_iter=1000, alpha=0.01),\n",
        "    RidgeGD(gd_type='Adagrad', max_iter=1000, alpha=0.01, eta=1000),\n",
        "]\n",
        "# train_target1, test_target1\n",
        "# train_scaled1\n",
        "# test_scaled1\n",
        "for model in models:\n",
        "    model.fit(train_scaled1, train_target1)\n",
        "    y_pred = model.predict(test_scaled1)\n",
        "    # Оценить качество модели, например, с помощью (MSE)\n",
        "sklearn_model = Ridge(alpha=0.01, max_iter=1000)\n",
        "sklearn_model.fit(train_scaled1, train_target1)\n",
        "y_sklearn_pred = sklearn_model.predict(test_scaled1)\n",
        "sklearn_mse = mean_squared_error(test_target1, y_sklearn_pred)\n",
        "for i, model in enumerate(models):\n",
        "    model_mse = mean_squared_error(test_target1, models[i].predict(test_scaled1))\n",
        "    model_r2 = r2_score(test_target1, models[i].predict(test_scaled1))\n",
        "    print(f\"RidgeGD ({model.gd_type}): MSE = {model_mse}, R^2 = {model_r2}, Sklearn Ridge: MSE = {sklearn_mse}\")\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bqYtVqv-y-Qu"
      },
      "source": [
        "#### 9. [1 балл] Постройте графики (там же) зависимости значения функции потерь от номера итерации для всех моделей (полного градиентого спуска, стохастического гс, Momentum и Adagrad). Сделайте выводы о скорости сходимости различных модификаций градиентного спуска.\n",
        "\n",
        "\n",
        "Не забывайте о том, как должен выглядеть *красивый* график!\n",
        "\n",
        "Выводы: GradientDecent и StohasticDescent практически одинаково сходятся и имеют ни самую лучшую сходимость из 4-х методов\n",
        "Momentum сходится же быстрее, чем GradientDecent и StohasticDescent. А самой высокой сходимостью обладает Adagrad, что видно на наших графиках"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Xbwhu8BSy-Qu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "outputId": "24bef448-02c8-4e36-a505-bfb6eeea736f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# your code here\n",
        "for model in models[:-1]:\n",
        "    plt.plot(range(len(model.loss_history[3:])), model.loss_history[3:], label=f'{model.gd_type}')\n",
        "plt.xlabel('Итерации')\n",
        "plt.ylabel('Значение функции потерь')\n",
        "plt.title('Зависимость функции потерь от номера итерации')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(range(len(models[-1].loss_history)), models[-1].loss_history, label=f'{models[-1].gd_type}')\n",
        "plt.xlabel('Итерации')\n",
        "plt.ylabel('Значение функции потерь')\n",
        "plt.title('Зависимость функции потерь от номера итерации')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "#╰( ͡° ͜ʖ ͡° )つ──☆*:・ﾟ"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}